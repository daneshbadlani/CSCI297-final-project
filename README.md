# Final Project

* Danesh Badlani
* Sam Bluestone
* Leslie Le
* Joe Salerno


## Dataset and Study

A study on statistics taken from Portuguese school children. Given the children's performance in two core classes, Mathematics and Portuguese, the machine attempted to predict the children's performance in secondary school, which will help improve the quality of education and enhance school resource management.

The dataset contains eduactional statistics of 395 students with 33 features, 16 of these being non-numerical data. Although of these 16, depending on how you transform the data, at least 11 features can be defined as binary features. Also, there are no missing features within this dataset.

Consult raw-data/student.md for all of the descriptions and names of the features within the dataset and how these features are being defined - binary, nominal, or numeric. 


## Feature Transformation

We used the last three columns as the target features. These last three columns - G1, G2, and G3 - represent the student's first period score, second period score, and final score, respectively. We decided to compile these scores together by averaging the three scores for to create a singular target feature.

We also decided to binarize the following features:
* school
* sex
* address
* famsize
* Pstatus

An example of the reason we decided to binzarize these features was to allow for easy processing. For example, given a student with a 0 (i.e. false) in the sex feature, we and the program can determine the since the male feature is false, the student must be female, and vice versa. In other words, if a value for a feature is false, then it is the other variable that is defined within that feature; if the value is true, then the feature is defined as that value.

We decided against using a one-hot-encoding vector for these features because doing so may increase the processing time and the complexity of finding the correlations between features (due to all the new columns that will be created).


## Feature Selection

We used a **RandomForest feature** selector to determine which features were the most important towards determining the value of the target feature. According to the graph generated by the random forest, the top five features that was the most important to determining the target feature the most were 'absences', 'freetime', 'Fedu', 'goout', and 'health'.

The **heatmap correlation graph** is a large graph that shows the correlations between all the features against each other. Rather than comparing the number of features that can be found on the dataset, the heatmap compares a larger number of features due to the one-hot-encoding vector of the categorical features: Mjob,  Fjob, reason, and guardian. It is difficult to see individual values of the generated heatmap, but the top five features, according the heatmap, that are most correlated to the target feature are the mother's job type ('Mjob'): 'other' and 'services', 'Medu', 'romantic', 'Fedu', and 'health'.

According to the two feature selection algorithms, the aggreed on features that coorelate the most or the most important features to the target features are 'Fedu' and 'health'. We believe that we should not use many of the binary features or categorical features due to the features' low variances (the features do not provide assitance in predicting a correct model or the feature does not provide enough information).

## Feature Extraction

For the **Principal Component Analysis**, it is recommended that one hot encoded binary features should not be used in this algorithm. Due to this, we used only the continuous features in the PCA. [TBD].

The **Linear Discriminant Analysis** [TBD].
